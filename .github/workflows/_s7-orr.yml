name: "S7 - ORR (callee)"

on:
  workflow_call:
    inputs:
      ref:
        type: string
        required: false
        default: ""
      run_microbench:
        type: boolean
        required: false
        default: false
      run_tla:
        type: boolean
        required: false
        default: false

permissions:
  contents: read

concurrency:
  group: ${{ github.ref }}
  cancel-in-progress: true

defaults:
  run:
    shell: bash

env:
  PYTHONHASHSEED: "0"
  TZ: "UTC"
  LC_ALL: "C"
  LANG: "C.UTF-8"

jobs:
  t0_spec:
    name: t0_spec
    runs-on: ubuntu-22.04
    outputs:
      status: ${{ steps.manifest.outputs.status }}
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - name: Gate T0 - manifest integrity
        id: manifest
        run: |
          set -euo pipefail
          MAN="docs/DNA/Roadmap e Sprints/Q2/Sprint 7/s_7_filemap_v_7.json"
          OUT="out/obs_gatecheck/T0_discovery.json"
          mkdir -p "$(dirname "$OUT")"
          printf '%s\n' \
            'import json' \
            'import subprocess' \
            'from pathlib import Path' \
            '' \
            'MANIFEST = Path("docs/DNA/Roadmap e Sprints/Q2/Sprint 7/s_7_filemap_v_7.json")' \
            'OUT_PATH = Path("out/obs_gatecheck/T0_discovery.json")' \
            'OUT_PATH.parent.mkdir(parents=True, exist_ok=True)' \
            'result = {' \
            '    "gate": "T0",' \
            '    "status": "FAIL",' \
            '    "checked": 0,' \
            '    "missing": [],' \
            '    "badhash": [],' \
            '    "manifest": str(MANIFEST),' \
            '}' \
            'if not MANIFEST.exists() or MANIFEST.stat().st_size == 0:' \
            '    result["missing"].append(str(MANIFEST))' \
            'else:' \
            '    jq_proc = subprocess.run([' \
            '        "jq",' \
            '        "-c",' \
            '        ".[]? // .",' \
            '        str(MANIFEST),' \
            '    ], capture_output=True, text=True, check=False)' \
            '    if jq_proc.returncode != 0:' \
            '        result["badhash"].append({' \
            '            "path": str(MANIFEST),' \
            '            "error": jq_proc.stderr.strip() or "jq_parse_error",' \
            '        })' \
            '    else:' \
            '        for raw_line in jq_proc.stdout.splitlines():' \
            '            if not raw_line.strip():' \
            '                continue' \
            '            try:' \
            '                entry = json.loads(raw_line)' \
            '            except json.JSONDecodeError as exc:' \
            '                result["badhash"].append({' \
            '                    "path": raw_line,' \
            '                    "error": f"json:{exc.msg}",' \
            '                })' \
            '                continue' \
            '            path_value = entry.get("path")' \
            '            expected_sha = (entry.get("sha1") or "").strip()' \
            '            if not path_value:' \
            '                continue' \
            '            candidate = Path(path_value)' \
            '            result["checked"] += 1' \
            '            if not candidate.is_file():' \
            '                result["missing"].append(str(candidate))' \
            '                continue' \
            '            hash_proc = subprocess.run([' \
            '                "git",' \
            '                "hash-object",' \
            '                "--",' \
            '                str(candidate),' \
            '            ], capture_output=True, text=True, check=False)' \
            '            if hash_proc.returncode != 0:' \
            '                result["badhash"].append({' \
            '                    "path": str(candidate),' \
            '                    "error": hash_proc.stderr.strip() or "hash_object_failed",' \
            '                })' \
            '                continue' \
            '            actual_sha = hash_proc.stdout.strip()' \
            '            if expected_sha and actual_sha and expected_sha.lower() != actual_sha.lower():' \
            '                result["badhash"].append({' \
            '                    "path": str(candidate),' \
            '                    "expected": expected_sha,' \
            '                    "actual": actual_sha,' \
            '                })' \
            'if not result["missing"] and not result["badhash"]:' \
            '    result["status"] = "PASS"' \
            'OUT_PATH.write_text(json.dumps(result, indent=2), encoding="utf-8")' \
            'print(result["status"])' \
            > .github/tmp_t0_manifest.py
          status=$(python .github/tmp_t0_manifest.py)
          rm -f .github/tmp_t0_manifest.py
          printf 'status=%s\n' "$status" >> "$GITHUB_OUTPUT"
      - name: Upload T0 evidence
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t0-evidence
          path: out/obs_gatecheck/T0_discovery.json
      - name: Fail on T0 discovery issues
        if: steps.manifest.outputs.status == 'FAIL'
        run: |
          echo "::error::T0 manifest checks failed. Review artifact 's7-t0-evidence' (out/obs_gatecheck/T0_discovery.json)"
          exit 1

  t1b_actionlint:
    name: t1b_actionlint
    needs: t0_spec
    runs-on: ubuntu-22.04
    outputs:
      status: ${{ steps.alint.outputs.status }}
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - name: Install actionlint (tarball)
        run: |
          set -euo pipefail
          ver="1.7.1"
          url="https://github.com/rhysd/actionlint/releases/download/v${ver}/actionlint_${ver}_linux_amd64.tar.gz"
          curl -fsSL "$url" -o actionlint.tgz
          tar -xzf actionlint.tgz actionlint
          sudo install -m 0755 actionlint /usr/local/bin/actionlint
          actionlint -version
      - name: Run actionlint
        id: alint
        run: |
          set -euo pipefail
          mkdir -p out/evidence/T1b_actionlint
          set +e
          actionlint -color 2>&1 | tee out/evidence/T1b_actionlint/actionlint.txt
          rc=${PIPESTATUS[0]}
          set -e
          status="PASS"; [ "$rc" -ne 0 ] && status="FAIL"
          echo "status=$status" >> "$GITHUB_OUTPUT"
      - if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t1b-actionlint
          path: out/evidence/T1b_actionlint
      - name: Fail on actionlint issues
        if: steps.alint.outputs.status == 'FAIL'
        run: |
          echo "::error::actionlint reported issues. Review s7-t1b-actionlint artifact."
          exit 1

  t1_yaml:
    name: t1_yaml
    needs: t0_spec
    runs-on: ubuntu-22.04
    outputs:
      status: ${{ steps.yamllint_post.outputs.status }}
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38
        with:
          python-version: '3.11'
      - name: Install yamllint
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install yamllint==1.35.1 ruamel.yaml==0.18.6
      - name: yamllint (initial)
        id: yamllint_initial
        run: |
          set -euo pipefail
          mkdir -p out/evidence/T1_yaml
          printf '{"attempts": []}\n' > out/evidence/T1_yaml/autofix_report.json
          printf 'no changes\n' > out/evidence/T1_yaml/autofix.diff
          : > out/evidence/T1_yaml/autofix_git_status.txt
          set +e
          yamllint -f parsable . | tee out/evidence/T1_yaml/yamllint.txt
          rc=${PIPESTATUS[0]}
          set -e
          printf '%s\n' "$rc" > out/evidence/T1_yaml/exit_code_initial.txt
          printf 'initial_rc=%s\n' "$rc" >> "$GITHUB_OUTPUT"
      - name: Apply YAML autofix for simple issues
        if: steps.yamllint_initial.outputs.initial_rc != '0'
        id: yamllint_autofix
        run: |
          set -euo pipefail
          printf '%s\n' \
            'import json' \
            'import re' \
            'from pathlib import Path' \
            '' \
            "LOG_PATH = Path('out/evidence/T1_yaml/yamllint.txt')" \
            "REPORT_PATH = Path('out/evidence/T1_yaml/autofix_report.json')" \
            '' \
            'simple_rules = {' \
            "    'indentation'," \
            "    'trailing-spaces'," \
            "    'trailing-space'," \
            "    'new-line-at-end-of-file'," \
            "    'new-lines'," \
            "    'document-start'," \
            "    'empty-lines'," \
            "    'braces'," \
            '}' \
            '' \
            'targets = {}' \
            "pattern = re.compile(r'^(?P<path>[^:]+):\\d+:\\d+:\\s+(?P<level>\\w+):.*\\((?P<rule>[^)]+)\\)')" \
            "for line in LOG_PATH.read_text(encoding='utf-8', errors='ignore').splitlines():" \
            '    match = pattern.match(line)' \
            '    if not match:' \
            '        continue' \
            "    rule = match.group('rule')" \
            '    if rule not in simple_rules:' \
            '        continue' \
            "    path = Path(match.group('path'))" \
            '    targets.setdefault(path, set()).add(rule)' \
            '' \
            'from ruamel.yaml import YAML' \
            'yaml = YAML()' \
            'yaml.preserve_quotes = True' \
            'yaml.width = 4096' \
            'yaml.indent(mapping=2, sequence=4, offset=2)' \
            '' \
            'results = []' \
            'for path, rules in targets.items():' \
            '    entry = {"path": str(path), "rules": sorted(rules), "status": "skipped"}' \
            '    try:' \
            '        text = path.read_text(encoding="utf-8")' \
            '    except FileNotFoundError:' \
            '        entry["status"] = "missing"' \
            '        results.append(entry)' \
            '        continue' \
            '    try:' \
            '        data = yaml.load(text)' \
            '    except Exception as exc:' \
            '        entry["status"] = "error"' \
            '        entry["error"] = f"load:{exc}"' \
            '        results.append(entry)' \
            '        continue' \
            '    if data is None:' \
            '        entry["status"] = "empty"' \
            '        results.append(entry)' \
            '        continue' \
            '    try:' \
            '        with path.open("w", encoding="utf-8") as handle:' \
            '            yaml.dump(data, handle)' \
            '        entry["status"] = "formatted"' \
            '    except Exception as exc:' \
            '        entry["status"] = "error"' \
            '        entry["error"] = f"dump:{exc}"' \
            '    results.append(entry)' \
            '' \
            'REPORT_PATH.write_text(json.dumps({"attempts": results}, indent=2), encoding="utf-8")' \
            > .github/tmp_t1_autofix.py
          python .github/tmp_t1_autofix.py
          rm -f .github/tmp_t1_autofix.py
          git status --short > out/evidence/T1_yaml/autofix_git_status.txt || true
          git diff > out/evidence/T1_yaml/autofix.diff || true
          if [ ! -s out/evidence/T1_yaml/autofix.diff ]; then
            printf 'no changes\n' > out/evidence/T1_yaml/autofix.diff
          fi
      - name: yamllint (post-fix)
        id: yamllint_post
        run: |
          set -euo pipefail
          mkdir -p out/evidence/T1_yaml
          set +e
          yamllint -f parsable . | tee out/evidence/T1_yaml/yamllint_post.txt
          rc=${PIPESTATUS[0]}
          set -e
          printf '%s\n' "$rc" > out/evidence/T1_yaml/exit_code_post.txt
          if [ "$rc" -eq 0 ]; then
            status="PASS"
            allow_manual_fix="true"
          else
            status="FAIL"
            allow_manual_fix="false"
          fi
          printf '%s\n' "$status" > out/evidence/T1_yaml/status.txt
          printf '%s\n' "$allow_manual_fix" > out/evidence/T1_yaml/ALLOW_MANUAL_FIX.txt
          printf 'status=%s\n' "$status" >> "$GITHUB_OUTPUT"
      - if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t1-yaml
          path: out/evidence/T1_yaml
      - name: Fail on YAML issues
        if: steps.yamllint_post.outputs.status == 'FAIL'
        run: |
          echo "::error::YAML validation failed. See s7-t1-yaml artifact for details."
          exit 1

  t2_security:
    name: t2_security
    needs: t0_spec
    runs-on: ubuntu-22.04
    outputs:
      status: ${{ steps.gitleaks.outputs.status }}
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - name: Install gitleaks
        run: |
          set -euo pipefail
          VER="8.18.1"
          URL="https://github.com/gitleaks/gitleaks/releases/download/v${VER}/gitleaks_${VER}_linux_x64.tar.gz"
          curl -fsSL "$URL" -o gitleaks.tgz
          tar -xzf gitleaks.tgz gitleaks
          sudo install -m 0755 gitleaks /usr/local/bin/gitleaks
          gitleaks version
      - name: Run gitleaks
        id: gitleaks
        run: |
          set -euo pipefail
          mkdir -p out/evidence/T2_security
          set +e
          gitleaks detect --source . --no-banner --redact --report-format json \
            --report-path out/evidence/T2_security/gitleaks_report.json
          rc=$?
          set -e
          printf '%s\n' "$rc" > out/evidence/T2_security/exit_code.txt
          if [ "$rc" -eq 0 ]; then
            status="PASS"
          else
            status="FAIL"
          fi
          echo "status=$status" >> "$GITHUB_OUTPUT"
      - name: Summarise gitleaks findings
        if: always()
        run: |
          set -euo pipefail
          report="out/evidence/T2_security/gitleaks_report.json"
          mkdir -p "$(dirname "$report")"
          if [ ! -s "$report" ]; then
            printf '{"findings": []}\n' > "$report"
          fi
          printf '%s\n' \
            'import json' \
            'from pathlib import Path' \
            '' \
            "report_path = Path('out/evidence/T2_security/gitleaks_report.json')" \
            "summary_path = Path('out/evidence/T2_security/gitleaks_summary.json')" \
            '' \
            'try:' \
            '    raw = json.loads(report_path.read_text(encoding="utf-8"))' \
            'except json.JSONDecodeError:' \
            '    raw = {"findings": []}' \
            '' \
            "findings = raw if isinstance(raw, list) else raw.get('findings', [])" \
            '' \
            'entries = []' \
            'for finding in findings:' \
            '    entries.append({' \
            "        'description': finding.get('description')," \
            "        'file': finding.get('file')," \
            "        'start_line': finding.get('startLine')," \
            "        'end_line': finding.get('endLine')," \
            "        'secret': bool(finding.get('secret'))," \
            "        'rule': finding.get('ruleID')," \
            '    })' \
            '' \
            'summary = {' \
            "    'total_findings': len(entries)," \
            "    'entries': entries," \
            '}' \
            'summary_path.write_text(json.dumps(summary, indent=2), encoding="utf-8")' \
            > .github/tmp_t2_summary.py
          python .github/tmp_t2_summary.py
          rm -f .github/tmp_t2_summary.py
      - if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t2-security
          path: out/evidence/T2_security
      - name: Fail on gitleaks findings
        if: steps.gitleaks.outputs.status == 'FAIL'
        run: |
          echo "::error::Gitleaks detected issues. Review s7-t2-security artifact."
          exit 1

  t3_pins:
    name: t3_pins
    needs:
      - t0_spec
      - t1b_actionlint
      - t1_yaml
      - t2_security
    runs-on: ubuntu-22.04
    outputs:
      status: ${{ steps.scan.outputs.status }}
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - name: scan pins
        id: scan
        run: |
          set -euo pipefail
          mkdir -p out/evidence/T3_pins
          if command -v rg >/dev/null 2>&1; then
            set +e
            rg --line-number -e 'uses:[[:space:]]*"?actions/.+@' .github/workflows | tee out/evidence/T3_pins/pins.txt
            rg_rc=${PIPESTATUS[0]}
            set -e
            if [ "$rg_rc" -gt 1 ]; then
              echo "rg failed with exit code $rg_rc" >&2
              exit "$rg_rc"
            fi
          else
            echo "[skip] ripgrep (rg) not installed" | tee out/evidence/T3_pins/pins.txt
          fi
          printf '%s\n' \
            'import json' \
            'import re' \
            'from pathlib import Path' \
            '' \
            'CANONICAL = {' \
            '    "actions/checkout": "11bd71901bbe5b1630ceea73d27597364c9af683",' \
            '    "actions/upload-artifact": "ea165f8d65b6e75b540449e92b4886f43607fa02",' \
            '    "actions/download-artifact": "d3f86a106a0bac45b974a628896c90dbdf5c8093",' \
            '    "actions/setup-python": "42375524e23c412d93fb67b49958b491fce71c38",' \
            '}' \
            '' \
            "pattern = re.compile(r'uses:\\s*\"?([\\w\\.-]+/[\\w\\.-]+)@([A-Za-z0-9]+)')" \
            'issues = []' \
            '' \
            'def is_sha(ref: str) -> bool:' \
            '    return bool(re.fullmatch(r"[0-9a-fA-F]{40}", ref))' \
            '' \
            'for path in Path(".github/workflows").rglob("*.yml"):' \
            '    for idx, line in enumerate(path.read_text(encoding="utf-8", errors="ignore").splitlines(), start=1):' \
            '        match = pattern.search(line)' \
            '        if not match:' \
            '            continue' \
            '        action, ref = match.groups()' \
            '        if action in CANONICAL:' \
            '            if CANONICAL[action] != ref:' \
            '                issues.append({' \
            '                    "file": str(path),' \
            '                    "line": idx,' \
            '                    "action": action,' \
            '                    "expected": CANONICAL[action],' \
            '                    "found": ref,' \
            '                    "reason": "non_canonical_sha",' \
            '                })' \
            '        elif action.startswith("actions/") and not is_sha(ref):' \
            '            issues.append({' \
            '                "file": str(path),' \
            '                "line": idx,' \
            '                "action": action,' \
            '                "found": ref,' \
            '                "reason": "unpinned_github_action",' \
            '            })' \
            '' \
            'out_dir = Path("out/evidence/T3_pins")' \
            'out_dir.mkdir(parents=True, exist_ok=True)' \
            'audit_path = out_dir / "pin_audit.json"' \
            '(out_dir / "canonical_map.json").write_text(json.dumps(CANONICAL, indent=2), encoding="utf-8")' \
            'audit_path.write_text(json.dumps({"issues": issues}, indent=2), encoding="utf-8")' \
            'print("FAIL" if issues else "PASS")' \
            > .github/tmp_t3_scan.py
          status=$(python .github/tmp_t3_scan.py)
          rm -f .github/tmp_t3_scan.py
          echo "status=$status" >> "$GITHUB_OUTPUT"
      - if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t3-pins
          path: out/evidence/T3_pins
      - name: Fail on pinning issues
        if: steps.scan.outputs.status == 'FAIL'
        run: |
          echo "::error::Non-canonical GitHub Action pin detected. Review s7-t3-pins artifact."
          exit 1

  t4_tests:
    name: t4_tests (py${{ matrix.py }})
    needs:
      - t0_spec
      - t1b_actionlint
      - t1_yaml
      - t2_security
    runs-on: ubuntu-22.04
    strategy:
      fail-fast: false
      matrix:
        py: ["3.11.9", "3.11.14"]
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38
        with:
          python-version: ${{ matrix.py }}
      - name: run pytest (if present)
        id: run_tests
        env:
          PY_VERSION: ${{ matrix.py }}
        run: |
          set -euo pipefail
          out_dir="out/evidence/T4_tests/${PY_VERSION}"
          mkdir -p "$out_dir"
          status="SKIP"
          pip_upgrade_rc=0
          pip_install_rc=0
          freeze_rc=0
          pytest_rc=0
          export TZ="UTC"
          export PYTHONHASHSEED="0"
          export PYTHONIOENCODING="utf-8"
          export PYTHONUNBUFFERED="1"
          export MPLBACKEND="Agg"
          export DETERMINISTIC_SEED="1337"
          printf '%s\n' \
            'import os' \
            'import random' \
            '' \
            'SEED = int(os.environ.get("DETERMINISTIC_SEED", "1337"))' \
            'random.seed(SEED)' \
            '' \
            'try:' \
            '    import numpy  # noqa: F401' \
            'except Exception:' \
            '    numpy = None' \
            'if numpy is not None:' \
            '    try:' \
            '        numpy.random.seed(SEED)' \
            '    except Exception:' \
            '        pass' \
            '' \
            'try:' \
            '    import torch' \
            'except Exception:' \
            '    torch = None' \
            'if torch is not None:' \
            '    try:' \
            '        torch.manual_seed(SEED)' \
            "        if hasattr(torch, 'cuda'):" \
            '            torch.cuda.manual_seed_all(SEED)' \
            '    except Exception:' \
            '        pass' \
            '' \
            'os.environ.setdefault("TZ", "UTC")' \
            > sitecustomize.py
          if [ -d tests ]; then
            status="PASS"
            set +e
            python -m pip install --upgrade pip 2>&1 | tee "$out_dir/pip-upgrade.log"
            pip_upgrade_rc=${PIPESTATUS[0]}
            if { [ -f pyproject.toml ] && grep -Eq "\[project\]|\[tool.poetry\]" pyproject.toml; } || \
               { [ -f setup.cfg ] && grep -Eq "\[metadata\]|\[options\]" setup.cfg; } || \
               [ -f setup.py ]; then
              python -m pip install ".[dev]" 2>&1 | tee "$out_dir/pip-install.log"; pip_install_rc=${PIPESTATUS[0]}
            elif [ -f requirements-dev.txt ]; then
              python -m pip install -r requirements-dev.txt 2>&1 | tee "$out_dir/pip-install.log"; pip_install_rc=${PIPESTATUS[0]}
            elif [ -f requirements.txt ]; then
              python -m pip install -r requirements.txt 2>&1 | tee "$out_dir/pip-install.log"; pip_install_rc=${PIPESTATUS[0]}
            else
              python -m pip install pytest 2>&1 | tee "$out_dir/pip-install.log"; pip_install_rc=${PIPESTATUS[0]}
            fi
            pip freeze > "$out_dir/requirements-freeze.txt"
            freeze_rc=$?
            pytest -q 2>&1 | tee "$out_dir/pytest.txt"
            pytest_rc=${PIPESTATUS[0]}
            set -e
            printf '%s\n' "$pytest_rc" > "$out_dir/pytest-exit-code.txt"
            if [ "$pip_upgrade_rc" -ne 0 ] || [ "$pip_install_rc" -ne 0 ] || [ "$pytest_rc" -ne 0 ] || [ "$freeze_rc" -ne 0 ]; then
              status="FAIL"
            fi
          else
            echo "skip: no tests directory present" | tee "$out_dir/pytest.txt"
            printf 'skip\n' > "$out_dir/pytest-exit-code.txt"
            printf 'skip\n' > "$out_dir/requirements-freeze.txt"
          fi
          echo "status=$status" >> "$GITHUB_OUTPUT"
      - if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t4-tests
          path: out/evidence/T4_tests
      - name: Fail on pytest errors
        if: steps.run_tests.outputs.status == 'FAIL'
        run: |
          echo "::error::pytest failed for Python ${{ matrix.py }}. See s7-t4-tests artifact."
          exit 1

  t5_props:
    name: t5_props
    needs:
      - t0_spec
      - t1b_actionlint
      - t1_yaml
      - t2_security
    runs-on: ubuntu-22.04
    outputs:
      status: ${{ steps.placeholder.outputs.status }}
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - name: Placeholder properties report
        id: placeholder
        run: |
          set -euo pipefail
          mkdir -p out/evidence/T5_props
          printf '%s\n' 'TODO: implementar propriedades' > out/evidence/T5_props/props.txt
          echo "status=TODO" >> "$GITHUB_OUTPUT"
      - if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t5-props
          path: out/evidence/T5_props

  t6_determinism:
    name: t6_determinism (py${{ matrix.py }})
    needs:
      - t0_spec
      - t1b_actionlint
      - t1_yaml
      - t2_security
    runs-on: ubuntu-22.04
    strategy:
      fail-fast: false
      matrix:
        py: ["3.11.9", "3.11.14"]
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38
        with:
          python-version: ${{ matrix.py }}
      - name: Determinism placeholder
        id: det
        env:
          PY_VERSION: ${{ matrix.py }}
        run: |
          set -euo pipefail
          out_dir="out/evidence/T6_determinism/${PY_VERSION}"
          mkdir -p "$out_dir"
          export OUT_DIR="$out_dir"
          export TZ="UTC"
          export PYTHONHASHSEED="0"
          export PYTHONIOENCODING="utf-8"
          export PYTHONUNBUFFERED="1"
          export MPLBACKEND="Agg"
          export DETERMINISTIC_SEED="1337"
          printf '%s\n' \
            'import os' \
            'import random' \
            '' \
            'SEED = int(os.environ.get("DETERMINISTIC_SEED", "1337"))' \
            'random.seed(SEED)' \
            '' \
            'try:' \
            '    import numpy' \
            'except Exception:' \
            '    numpy = None' \
            'if numpy is not None:' \
            '    try:' \
            '        numpy.random.seed(SEED)' \
            '    except Exception:' \
            '        pass' \
            '' \
            'try:' \
            '    import torch' \
            'except Exception:' \
            '    torch = None' \
            'if torch is not None:' \
            '    try:' \
            '        torch.manual_seed(SEED)' \
            "        if hasattr(torch, 'cuda'):" \
            '            torch.cuda.manual_seed_all(SEED)' \
            '    except Exception:' \
            '        pass' \
            '' \
            'os.environ.setdefault("TZ", "UTC")' \
            > sitecustomize.py
          printf '%s\n' \
            'import json' \
            'import os' \
            'import subprocess' \
            'import sys' \
            'from pathlib import Path' \
            '' \
            'out_dir = Path(os.environ["OUT_DIR"])' \
            'out_dir.mkdir(parents=True, exist_ok=True)' \
            'seed = int(os.environ.get("DETERMINISTIC_SEED", "1337"))' \
            '' \
            'CODE = """' \
            "import json, os, random" \
            "SEED = int(os.environ.get('DETERMINISTIC_SEED','1337'))" \
            'random.seed(SEED)' \
            'try:' \
            '    import numpy as _np' \
            'except Exception:' \
            '    _np = None' \
            'if _np is not None:' \
            '    try:' \
            '        _np.random.seed(SEED)' \
            '    except Exception:' \
            '        pass' \
            "payload={'seed':SEED,'series':[random.random() for _ in range(10)]}" \
            'if _np is not None:' \
            "    payload['matrix']=_np.random.rand(3,3).tolist()" \
            "print(json.dumps(payload,separators=(',',':')))" \
            '"""' \
            '' \
            'def run_attempt():' \
            '    env = os.environ.copy()' \
            '    env["DETERMINISTIC_SEED"] = str(seed)' \
            '    completed = subprocess.run([' \
            '        sys.executable,' \
            "        '-c'," \
            '        CODE,' \
            '    ], capture_output=True, text=True, check=True, env=env)' \
            '    return json.loads(completed.stdout)' \
            '' \
            'attempts = [run_attempt(), run_attempt()]' \
            'status = "PASS" if attempts[0] == attempts[1] else "FAIL"' \
            'summary = {' \
            "    'gate': 'T6'," \
            "    'python_version': os.environ.get('PY_VERSION')," \
            "    'status': status," \
            "    'attempts': attempts," \
            '}' \
            '(out_dir / "det_report.json").write_text(json.dumps(summary, indent=2), encoding="utf-8")' \
            '(out_dir / "status.txt").write_text(f"{status}\\n", encoding="utf-8")' \
            'print(status)' \
            > .github/tmp_t6_runner.py
          status=$(python .github/tmp_t6_runner.py)
          rm -f .github/tmp_t6_runner.py
          printf 'status=%s\n' "$status" >> "$GITHUB_OUTPUT"
      - if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t6-determinism
          path: out/evidence/T6_determinism

  t7_append_only:
    name: t7_append_only
    needs:
      - t0_spec
      - t1b_actionlint
      - t1_yaml
      - t2_security
    runs-on: ubuntu-22.04
    outputs:
      status: ${{ steps.guard.outputs.status }}
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - name: append-only guard
        id: guard
        run: |
          set -euo pipefail
          mkdir -p out/evidence/T7_append_only
          mkdir -p obs/guards/append_only/baseline
          mkdir -p obs/guards/append_only_exceptions
          printf '%s\n' \
            'import json' \
            'import shutil' \
            'import subprocess' \
            'from pathlib import Path' \
            '' \
            "BASE_DIR = Path('obs/guards/append_only/baseline')" \
            "LEDGER_DIR = Path('obs/guards/append_only_exceptions')" \
            "REPORT_TXT = Path('out/evidence/T7_append_only/report.txt')" \
            "REPORT_JSON = Path('out/evidence/T7_append_only/report.json')" \
            'BASE_DIR.mkdir(parents=True, exist_ok=True)' \
            'LEDGER_DIR.mkdir(parents=True, exist_ok=True)' \
            '' \
            'def git_ls(patterns):' \
            "    result = subprocess.run(['git','ls-files',*patterns], capture_output=True, text=True, check=False)" \
            '    if result.returncode not in (0, 1):' \
            "        raise RuntimeError(f'git ls-files failed: {result.stderr}')" \
            '    return [Path(line) for line in result.stdout.splitlines() if line.strip()]' \
            '' \
            "targets = git_ls(['data/**/*.jsonl','data/**/*.ndjson'])" \
            'ledger_entries = {}' \
            'for entry_path in sorted(LEDGER_DIR.glob("*.json")):' \
            '    try:' \
            '        payload = json.loads(entry_path.read_text(encoding="utf-8"))' \
            '    except json.JSONDecodeError as exc:' \
            "        ledger_entries.setdefault('__ledger_errors__', []).append({'file': str(entry_path), 'error': f'json:{exc.msg}'})" \
            '        continue' \
            '    items = payload if isinstance(payload, list) else [payload]' \
            '    for item in items:' \
            "        path = item.get('path')" \
            "        sha1 = (item.get('sha1') or '').lower()" \
            "        signature = item.get('signature')" \
            '        if not path or not sha1 or not signature:' \
            "            ledger_entries.setdefault('__ledger_errors__', []).append({'file': str(entry_path), 'error': 'missing_fields'})" \
            '            continue' \
            "        ledger_entries.setdefault(path, []).append({'sha1': sha1, 'signature': signature})" \
            '' \
            "entries = []" \
            "overall_status = 'PASS'" \
            'def compute_sha(candidate):' \
            "    return subprocess.run(['git','hash-object','--',str(candidate)], capture_output=True, text=True, check=True).stdout.strip().lower()" \
            'def normalise_lines(candidate):' \
            "    return [line.rstrip('\\n').rstrip() for line in candidate.read_text(encoding='utf-8').splitlines()]" \
            '' \
            'if not targets:' \
            "    overall_status = 'SKIP'" \
            "    REPORT_TXT.write_text('no append-only targets found\\n', encoding='utf-8')" \
            'else:' \
            '    lines = []' \
            '    for target in targets:' \
            "        safe_name = target.as_posix().replace('/', '__') + '.baseline'" \
            '        baseline = BASE_DIR / safe_name' \
            "        current_entry = {'path': target.as_posix(), 'baseline': baseline.as_posix(), 'status': 'UNKNOWN', 'exception_used': None}" \
            '        if not target.exists():' \
            "            current_entry['status'] = 'MISSING'" \
            "            overall_status = 'FAIL'" \
            '            entries.append(current_entry)' \
            "            lines.append(f"FAIL: missing target {target.as_posix()}")" \
            '            continue' \
            '        if not baseline.exists():' \
            '            baseline.parent.mkdir(parents=True, exist_ok=True)' \
            '            shutil.copy2(target, baseline)' \
            "            current_entry['status'] = 'BASELINE_CREATED'" \
            "            overall_status = 'FAIL'" \
            '            entries.append(current_entry)' \
            "            lines.append(f"FAIL: baseline generated for {target.as_posix()}")" \
            '            continue' \
            '        baseline_lines = normalise_lines(baseline)' \
            '        target_lines = normalise_lines(target)' \
            '        baseline_sha = compute_sha(baseline)' \
            '        target_sha = compute_sha(target)' \
            "        current_entry['baseline_sha1'] = baseline_sha" \
            "        current_entry['current_sha1'] = target_sha" \
            '        if len(target_lines) < len(baseline_lines) or target_lines[:len(baseline_lines)] != baseline_lines:' \
            "            ledger = ledger_entries.get(target.as_posix(), [])" \
            "            exception = next((item for item in ledger if item['sha1'] == target_sha), None)" \
            '            if exception:' \
            "                current_entry['status'] = 'EXCEPTION'" \
            "                current_entry['exception_used'] = exception" \
            "                lines.append(f"WARN: non-append change allowed for {target.as_posix()} via {exception['signature']}")" \
            '            else:' \
            "                current_entry['status'] = 'FAIL'" \
            "                overall_status = 'FAIL'" \
            "                lines.append(f"FAIL: non-append change detected in {target.as_posix()}")" \
            '        else:' \
            "            current_entry['status'] = 'PASS'" \
            "            lines.append(f"OK: append-only preserved {target.as_posix()}")" \
            '        entries.append(current_entry)' \
            '    for baseline_file in BASE_DIR.glob("*.baseline"):' \
            "        rel = baseline_file.name[:-9].replace('__', '/')" \
            '        if not Path(rel).exists():' \
            "            overall_status = 'FAIL'" \
            "            entries.append({'path': rel, 'baseline': baseline_file.as_posix(), 'status': 'ORPHAN_BASELINE', 'exception_used': None})" \
            "            lines.append(f"FAIL: baseline has no matching target for {rel}")" \
            "    REPORT_TXT.write_text('\n'.join(lines) + ('\n' if lines else ''), encoding='utf-8')" \
            '' \
            "if ledger_entries.get('__ledger_errors__'):" \
            "    overall_status = 'FAIL'" \
            "    for error in ledger_entries['__ledger_errors__']:" \
            "        entries.append({'path': '__ledger__', 'baseline': '', 'status': 'LEDGER_ERROR', 'error': error, 'exception_used': None})" \
            '' \
            "summary = {'gate': 'T7', 'status': overall_status, 'entries': entries}" \
            'REPORT_JSON.write_text(json.dumps(summary, indent=2), encoding="utf-8")' \
            'print(overall_status)' \
            > .github/tmp_t7_guard.py
          status=$(python .github/tmp_t7_guard.py)
          rm -f .github/tmp_t7_guard.py
          printf 'status=%s\n' "$status" >> "$GITHUB_OUTPUT"
      - if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-t7-append-only
          path: out/evidence/T7_append_only
      - name: Fail on append-only issues
        if: steps.guard.outputs.status == 'FAIL'
        run: |
          echo "::error::Append-only guard failed. Review s7-t7-append-only artifact."
          exit 1

  t8_pack:
    name: t8_pack
    needs:
      - t0_spec
      - t1b_actionlint
      - t1_yaml
      - t2_security
      - t3_pins
      - t4_tests
      - t5_props
      - t6_determinism
      - t7_append_only
    if: always()
    runs-on: ubuntu-22.04
    env:
      GATES_CONTEXT: ${{ toJSON(needs) }}
    steps:
      - name: Checkout (ref)
        if: inputs.ref != ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          ref: ${{ inputs.ref }}
          fetch-depth: 0
      - name: Checkout (default)
        if: inputs.ref == ''
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 0
      - name: pack bundle
        run: |
          set -euo pipefail
          mkdir -p out/orr_bundle
          printf '%s\n' \
            'import json' \
            'import os' \
            'from pathlib import Path' \
            '' \
            'MAPPING = [' \
            "    ('T0', 't0_spec', 's7-t0-evidence')," \
            "    ('T1B', 't1b_actionlint', 's7-t1b-actionlint')," \
            "    ('T1', 't1_yaml', 's7-t1-yaml')," \
            "    ('T2', 't2_security', 's7-t2-security')," \
            "    ('T3', 't3_pins', 's7-t3-pins')," \
            "    ('T4', 't4_tests', 's7-t4-tests')," \
            "    ('T5', 't5_props', 's7-t5-props')," \
            "    ('T6', 't6_determinism', 's7-t6-determinism')," \
            "    ('T7', 't7_append_only', 's7-t7-append-only')," \
            ']' \
            '' \
            'RESULT_MAP = {' \
            "    'success': 'PASS'," \
            "    'failure': 'FAIL'," \
            "    'failed': 'FAIL'," \
            "    'cancelled': 'CANCELLED'," \
            "    'skipped': 'SKIP'," \
            '}' \
            '' \
            'needs_context = json.loads(os.environ.get("GATES_CONTEXT", "{}"))' \
            '' \
            'def resolve_status(node):' \
            '    outputs = node.get("outputs", {}) if isinstance(node, dict) else {}' \
            '    status_value = str(outputs.get("status", "")) if outputs.get("status") is not None else ""' \
            '    status_value = status_value.strip()' \
            '    if status_value:' \
            '        return status_value' \
            '    result_value = str(node.get("result", "")) if isinstance(node, dict) else ""' \
            '    result_value = result_value.strip().lower()' \
            '    if result_value in RESULT_MAP:' \
            '        return RESULT_MAP[result_value]' \
            '    return result_value.upper() if result_value else "UNKNOWN"' \
            '' \
            'gates = []' \
            'for gate_name, key, artifact in MAPPING:' \
            '    node = needs_context.get(key, {})' \
            '    status = resolve_status(node)' \
            '    gates.append({' \
            "        'gate': gate_name," \
            "        'status': status," \
            "        'artifact': artifact," \
            '    })' \
            '' \
            'counts = {}' \
            'for entry in gates:' \
            "    counts[entry['status']] = counts.get(entry['status'], 0) + 1" \
            '' \
            'summary = {' \
            "    'run_id': os.environ.get('GITHUB_RUN_ID')," \
            "    'run_attempt': os.environ.get('GITHUB_RUN_ATTEMPT')," \
            "    'gates': gates," \
            "    'status_counts': counts," \
            '}' \
            "Path('out/orr_bundle/summary.json').write_text(json.dumps(summary, indent=2), encoding='utf-8')" \
            > .github/tmp_t8_pack.py
          python .github/tmp_t8_pack.py
          rm -f .github/tmp_t8_pack.py
      - uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: s7-orr-evidence
          path: out/orr_bundle
