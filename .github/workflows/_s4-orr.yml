# ---------- .github/workflows/_s4-orr.yml ----------
name: _s4-orr

on:
  workflow_call:
    inputs:
      ref:
        description: Optional ref to run against
        required: false
        type: string
      run_microbench:
        description: Enable microbench gate
        required: false
        type: boolean
        default: false
      run_tla:
        description: Enable TLA verification
        required: false
        type: boolean
        default: false

concurrency:
  group: s4-orr-${{ inputs.ref || github.sha }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: write
  id-token: write

jobs:
  orr:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    env:
      PROM_URL: http://127.0.0.1:9090

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.sha }}

      - name: Harden runner
        uses: step-security/harden-runner@v2
        with:
          egress-policy: audit

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install jq
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq

      # -------- Python deps (dbt only) + auditoria --------
      - name: Install Python deps (dbt only)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "dbt-core==1.6.4" "dbt-bigquery==1.6.4" "requests==2.31.0"

      - name: Python env audit
        run: |
          set -euo pipefail
          mkdir -p out/pip-audit
          python -m pip --version | tee out/pip-audit/pip-version.txt
          pip freeze | sort | tee out/pip-audit/pip-freeze.txt

      - name: Upload pip audit
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit
          path: out/pip-audit

      # -------- Ferramentas de segurança (binários) --------
      - name: Install security tools (Trivy & Gitleaks)
        run: |
          set -euo pipefail
          curl -sSL https://github.com/gitleaks/gitleaks/releases/download/v8.18.4/gitleaks_8.18.4_linux_x64.tar.gz | tar xz
          sudo install -m 0755 gitleaks /usr/local/bin/gitleaks
          rm -f gitleaks LICENSE README.md || true

          curl -sSL https://github.com/aquasecurity/trivy/releases/download/v0.53.0/trivy_0.53.0_Linux-64bit.tar.gz | tar xz
          sudo install -m 0755 trivy /usr/local/bin/trivy
          rm -f trivy LICENSE README.md || true

      - name: Semgrep (container v1.80.0, pinned digest)
        run: |
          set -euo pipefail
          SEMGREP_IMG="semgrep/semgrep:1.80.0-nonroot@sha256:a80fcd5ce03772efeca8fc58f0eeb7ede05c228c8b12c1e078601a4f52de75a4"
          docker pull "$SEMGREP_IMG" >/dev/null
          docker run --rm -v "$PWD:/src" -w /src "$SEMGREP_IMG" semgrep --version
          # opcional: varredura
          # docker run --rm -v "$PWD:/src" -w /src "$SEMGREP_IMG" semgrep --config auto --error --timeout 120 .

      # -------- Node (opcional) --------
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install npm deps
        run: |
          set -euo pipefail
          if [ -f package-lock.json ] || [ -f npm-shrinkwrap.json ]; then
            npm ci --ignore-scripts
          else
            echo "no package-lock.json; skipping npm ci"
          fi

      # -------- k6 por digest pinado --------
      - name: Resolve k6 digest
        id: k6
        run: |
          set -euo pipefail
          IMAGE=grafana/k6:0.52.0
          docker pull "$IMAGE" >/dev/null
          DIGEST=$(docker inspect --format='{{index .RepoDigests 0}}' "$IMAGE")
          echo "image=$DIGEST" >> "$GITHUB_OUTPUT"

      # -------- dbt build → dbt docs (somente se houver projeto dbt) --------
      - name: Locate dbt project
        id: dbt
        run: |
          set -euo pipefail
          DBT_DIR=$(find . -type f -name dbt_project.yml | head -n1 | xargs -r dirname)
          if [ -n "$DBT_DIR" ]; then
            echo "dir=$DBT_DIR" >> "$GITHUB_OUTPUT"
            echo "Found dbt project at $DBT_DIR"
          else
            echo "dir=" >> "$GITHUB_OUTPUT"
            echo "No dbt project found; skipping dbt steps."
          fi

      - name: Configure BigQuery credentials for dbt (if secrets present)
        id: bq
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.GCP_SA_JSON || '' }}" ] && [ -n "${{ secrets.DBT_BQ_PROJECT || '' }}" ]; then
            echo "have_secrets=true" >> "$GITHUB_OUTPUT"
          else
            echo "have_secrets=false" >> "$GITHUB_OUTPUT"
          fi
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}

      - name: dbt deps
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt deps --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}

      - name: dbt build
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt build --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}

      - name: dbt docs generate
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt docs generate --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}

      - name: Upload dbt docs
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: dbt-docs
          path: |
            ${{ steps.dbt.outputs.dir }}/target/catalog.json
            ${{ steps.dbt.outputs.dir }}/target/manifest.json
            ${{ steps.dbt.outputs.dir }}/target/index.html

      # -------- Microbench gate (opcional) --------
      - name: Microbench (gate)
        if: ${{ inputs.run_microbench }}
        run: |
          set -euo pipefail
          bash scripts/microbench_dec.sh
          # Valida limiares (sem flakiness)
          awk '/match_core.*mean/ {m=$2+0} END { if (m>1.20) { print "match_core mean>1.20ms"; exit 1 } }' out/s4_orr/logs/microbench.txt
          awk '/route_fast.*mean/ {m=$2+0} END { if (m>0.70) { print "route_fast mean>0.70ms"; exit 1 } }' out/s4_orr/logs/microbench.txt
          awk '/twap_update.*mean/ {m=$2+0} END { if (m>0.45) { print "twap_update mean>0.45ms"; exit 1 } }' out/s4_orr/logs/microbench.txt

      # -------- TLA check (opcional) --------
      - name: TLA check (Apalache)
        if: ${{ inputs.run_tla }}
        run: |
          set -euo pipefail
          mkdir -p out/s4_orr
          docker run --rm -v "$PWD/docs/spec/tla:/work" ghcr.io/informalsystems/apalache:0.46.2 check dec_pre_ga.tla | tee out/s4_orr/tla_report.txt

      - name: Upload TLA report
        if: ${{ inputs.run_tla }}
        uses: actions/upload-artifact@v4
        with:
          name: tla-report
          path: out/s4_orr/tla_report.txt

      # -------- ORR principal --------
      - name: ORR run
        env:
          K6_IMAGE: ${{ steps.k6.outputs.image }}
        run: |
          set -euo pipefail
          export K6="docker run --rm -i -v $PWD:/work -w /work $K6_IMAGE"
          bash scripts/orr_s4_run.sh

      - name: Upload bundle
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: s4_evidence_bundle
          path: out/s4_evidence_bundle_*.zip
