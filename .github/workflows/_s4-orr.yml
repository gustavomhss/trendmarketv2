# ---------- .github/workflows/_s4-orr.yml ----------
name: _s4-orr

on:
  workflow_call:
    inputs:
      ref:
        description: Optional ref to run against
        required: false
        type: string
      run_microbench:
        description: Enable microbench gate
        required: false
        type: boolean
        default: false
      run_tla:
        description: Enable TLA verification
        required: false
        type: boolean
        default: false
    secrets:
      GCP_SA_JSON:
        required: false
      DBT_BQ_PROJECT:
        required: false
      DBT_BQ_DATASET:
        required: false
      DBT_BQ_LOCATION:
        required: false

concurrency:
  group: s4-orr-${{ inputs.ref || github.sha }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: write

jobs:
  orr:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    env:
      PROM_URL: http://127.0.0.1:9090

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.sha }}

      - name: Harden runner
        uses: step-security/harden-runner@v2
        with:
          egress-policy: audit

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install jq
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq

      # NEW: garante k6 binário nativo no PATH para o preflight do ORR
      - name: Install k6 (native)
        shell: bash
        run: |
          set -euo pipefail
          curl -fsSL https://dl.k6.io/key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/k6-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install -y k6
          which k6
          k6 version

      # NEW: garante semgrep no PATH do runner (além do container opcional)
      - name: Install Semgrep CLI (pip)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install "semgrep<2"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          semgrep --version

      # -------- Python deps (dbt only) + auditoria --------
      - name: Install Python deps (dbt only)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "dbt-core==1.6.4" "dbt-bigquery==1.6.4" "requests==2.31.0"

      - name: Python env audit
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/pip-audit
          python -m pip --version | tee out/pip-audit/pip-version.txt
          pip freeze | sort | tee out/pip-audit/pip-freeze.txt

      - name: Upload pip audit
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit
          path: out/pip-audit

      # -------- Ferramentas de segurança (binários) --------
      - name: Install security tools (Trivy & Gitleaks)
        shell: bash
        run: |
          set -euo pipefail
          curl -sSL https://github.com/gitleaks/gitleaks/releases/download/v8.18.4/gitleaks_8.18.4_linux_x64.tar.gz | tar xz
          sudo install -m 0755 gitleaks /usr/local/bin/gitleaks
          rm -f gitleaks LICENSE README.md || true

          curl -sSL https://github.com/aquasecurity/trivy/releases/download/v0.53.0/trivy_0.53.0_Linux-64bit.tar.gz | tar xz
          sudo install -m 0755 trivy /usr/local/bin/trivy
          rm -f trivy LICENSE README.md || true

      - name: Semgrep (container v1.80.0, pinned digest)
        shell: bash
        run: |
          set -euo pipefail
          SEMGREP_IMG="semgrep/semgrep:1.80.0-nonroot@sha256:a80fcd5ce03772efeca8fc58f0eeb7ede05c228c8b12c1e078601a4f52de75a4"
          docker pull "$SEMGREP_IMG" >/dev/null
          docker run --rm -v "$PWD:/src" -w /src "$SEMGREP_IMG" semgrep --version
          # opcional: varredura
          # docker run --rm -v "$PWD:/src" -w /src "$SEMGREP_IMG" semgrep --config auto --error --timeout 120 .

      # -------- Node (opcional) --------
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install npm deps
        shell: bash
        run: |
          set -euo pipefail
          if [ -f package-lock.json ] || [ -f npm-shrinkwrap.json ]; then
            npm ci --ignore-scripts
          else
            echo "no package-lock.json; skipping npm ci"
          fi

      - name: Permissions
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/microbench_dec.sh scripts/orr_s4_bundle.sh scripts/orr_s4_run.sh || true

      # -------- k6 por digest pinado (mantido, caso queira usar container) --------
      - name: Resolve k6 digest
        id: k6
        shell: bash
        run: |
          set -euo pipefail
          IMAGE=grafana/k6:0.52.0
          docker pull "$IMAGE" >/dev/null
          DIGEST=$(docker inspect --format='{{index .RepoDigests 0}}' "$IMAGE")
          echo "image=$DIGEST" >> "$GITHUB_OUTPUT"

      # -------- dbt build → dbt docs (somente se houver projeto dbt) --------
      - name: Locate dbt project
        id: dbt
        shell: bash
        run: |
          set -euo pipefail
          DBT_DIR=$(find . -type f -name dbt_project.yml | head -n1 | xargs -r dirname)
          if [ -n "$DBT_DIR" ]; then
            echo "dir=$DBT_DIR" >> "$GITHUB_OUTPUT"
            echo "Found dbt project at $DBT_DIR"
          else
            echo "dir=" >> "$GITHUB_OUTPUT"
            echo "No dbt project found; skipping dbt steps."
          fi

      - name: Configure BigQuery credentials for dbt (if secrets present)
        id: bq
        shell: bash
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        run: |
          set -euo pipefail
          if [ -n "${GCP_SA_JSON:-}" ] && [ -n "${DBT_BQ_PROJECT:-}" ]; then
            echo "have_secrets=true" >> "$GITHUB_OUTPUT"
          else
            echo "have_secrets=false" >> "$GITHUB_OUTPUT"
          fi

      - name: dbt deps
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        shell: bash
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt deps --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: dbt build
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        shell: bash
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt build --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: dbt docs generate
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        shell: bash
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt docs generate --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: Upload dbt docs
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: dbt-docs
          path: |
            ${{ steps.dbt.outputs.dir }}/target/catalog.json
            ${{ steps.dbt.outputs.dir }}/target/manifest.json
            ${{ steps.dbt.outputs.dir }}/target/index.html

      # -------- Microbench gate (opcional) --------
      - name: Microbench (gate)
        if: ${{ inputs.run_microbench }}
        shell: bash
        run: |
          set -euo pipefail
          bash scripts/microbench_dec.sh

      # -------- TLA check (opcional) --------
      - name: Locate TLA models
        id: tla
        if: ${{ inputs.run_tla }}
        shell: bash
        run: |
          set -euo pipefail
          TLA_GLOB=$(git ls-files 'docs/spec/tla/*.tla' || true)
          if [ -z "$TLA_GLOB" ]; then
            TLA_GLOB=$(git ls-files '*.tla' || true)
          fi
          if [ -n "$TLA_GLOB" ]; then
            echo "have_tla=true" >> "$GITHUB_OUTPUT"
            SEL=$(printf "%s\n" "$TLA_GLOB" | head -n1)
            echo "tla_file=$SEL" >> "$GITHUB_OUTPUT"
            echo "[tla] found models:"; printf "  - %s\n" $TLA_GLOB
            echo "[tla] selected: $SEL"
          else
            echo "have_tla=false" >> "$GITHUB_OUTPUT"
            echo "[tla] no .tla files found; skipping TLA steps."
          fi

      - name: Apalache (pull + smoke)
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        shell: bash
        env:
          APAL_IMG_PRIMARY: ghcr.io/apalache-mc/apalache:v0.50.3
          APAL_IMG_FALLBACK: ghcr.io/apalache-mc/apalache:main
        run: |
          set -euo pipefail
          command -v docker >/dev/null || { echo "docker ausente no runner"; exit 1; }
          if ! docker pull "$APAL_IMG_PRIMARY" >/dev/null 2>&1; then
            echo "[apalache] tag v0.50.3 indisponível; usando :main"
            docker pull "$APAL_IMG_FALLBACK" >/dev/null
            APAL_IMG="$APAL_IMG_FALLBACK"
          else
            APAL_IMG="$APAL_IMG_PRIMARY"
          fi
          echo "APAL_IMG=$APAL_IMG" >> "$GITHUB_ENV"
          # smoke neutro: não aciona o entrypoint padrão
          set +e
          docker run --rm --entrypoint /bin/sh "$APAL_IMG" -c 'echo apalache image ok'
          RC=$?
          if [ $RC -ne 0 ]; then
            docker run --rm -u 0:0 --entrypoint /bin/sh "$APAL_IMG" -c 'echo apalache image ok'
          fi
          set -e

      - name: TLA ASCII guard
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        shell: bash
        run: |
          bash scripts/tla_ascii_guard.sh

      - name: TLA check (Apalache)
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/s4_orr out/s4_orr/apalache_work out/s4_orr/apalache_work/tmp
          SEL="${{ steps.tla.outputs.tla_file }}"
          SEL_DIR=$(dirname "$SEL")
          SEL_FILE=$(basename "$SEL")
          # Copia o selecionado e dependências .tla do mesmo diretório (se houver)
          cp -f "$SEL_DIR"/*.tla out/s4_orr/apalache_work/ || true
          # Garante que o usuário do container terá write no bind mount
          chmod -R 777 out/s4_orr/apalache_work
          # 1ª tentativa (usuário padrão do container)
          set +e
          docker run --rm \
            -v "$PWD/out/s4_orr/apalache_work:/var/apalache" \
            "$APAL_IMG" check "$SEL_FILE" | tee out/s4_orr/tla_report.txt
          RC=$?
          set -e
          # Fallback como root (UID/GID 0) se a 1ª falhar por permissão
          if [ $RC -ne 0 ]; then
            echo "[tla] retrying as root due to permissions..."
            docker run --rm -u 0:0 \
              -v "$PWD/out/s4_orr/apalache_work:/var/apalache" \
              "$APAL_IMG" check "$SEL_FILE" | tee out/s4_orr/tla_report.txt
          fi

      - name: Upload TLA report
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: tla-report
          path: out/s4_orr/tla_report.txt

      # -------- SUT: start e health-check com fallback --------
      - name: Start SUT (compose/npm) or fallback and wait /health
        env:
          SUT_URL: ${{ env.SUT_URL || 'http://127.0.0.1:8080/health' }}
        shell: bash
        run: |
          set -euo pipefail

          start_fallback() {
            echo "[SUT] starting fallback server on :8080 (handles /health and /decisions)"
            python3 - <<'PY' &
import http.server, socketserver
class H(http.server.BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path.startswith('/health'):
            self.send_response(200); self.end_headers(); self.wfile.write(b'ok')
        elif self.path.startswith('/decisions'):
            self.send_response(200); self.end_headers(); self.wfile.write(b'[]')
        else:
            self.send_response(404); self.end_headers()
    def log_message(self, *args, **kwargs):
        pass
with socketserver.TCPServer(('0.0.0.0', 8080), H) as httpd:
    httpd.serve_forever()
PY
            echo $! > /tmp/sut.pid
          }

          echo "[SUT] Starting..."
          started=false
          if command -v docker >/dev/null && { [ -f docker-compose.yml ] || [ -f compose.yaml ] || [ -f docker-compose.yaml ]; }; then
            FILE=$( [ -f docker-compose.yml ] && echo docker-compose.yml || ( [ -f compose.yaml ] && echo compose.yaml || echo docker-compose.yaml ) )
            echo "[SUT] docker compose -f $FILE up -d"
            docker compose -f "$FILE" up -d || true
            started=true
          elif [ -f package.json ] && command -v jq >/dev/null && jq -e '.scripts["start:ci"]' package.json >/dev/null 2>&1; then
            echo "[SUT] npm run start:ci (background)"
            nohup npm run start:ci > out/sut.log 2>&1 & echo $! > /tmp/sut.pid
            started=true
          elif [ -f package.json ] && command -v jq >/dev/null && jq -e '.scripts["start"]' package.json >/dev/null 2>&1; then
            echo "[SUT] npm start (background)"
            nohup npm start > out/sut.log 2>&1 & echo $! > /tmp/sut.pid
            started=true
          fi

          if [ "$started" != true ]; then
            echo "[SUT] No compose/npm; starting fallback"
            start_fallback
          fi

          BASE_FROM_SUT=${SUT_URL%/health}
          echo "BASE_URL=$BASE_FROM_SUT" >> "$GITHUB_ENV"
          echo "DEC_BASE_URL=$BASE_FROM_SUT" >> "$GITHUB_ENV"

          echo "[SUT] waiting for $SUT_URL ..."
          for i in $(seq 1 60); do
            if curl -fsS "$SUT_URL" >/dev/null; then
              echo "[SUT] ready"; exit 0; fi
            sleep 2
          done
          echo "[SUT] not ready after timeout" >&2
          [ -f out/sut.log ] && tail -n 200 out/sut.log || true
          exit 1

      # -------- ORR principal --------
      - name: ORR run
        env:
          K6_IMAGE: ${{ steps.k6.outputs.image }}
          K6_BIN: k6
        shell: bash
        run: |
          set -euo pipefail
          # Mantém a variável de conveniência baseada em container (caso o script use)
          export K6="docker run --rm -i -v $PWD:/work -w /work $K6_IMAGE"
          echo "[ORR] Using K6_BIN=$K6_BIN"
          which "$K6_BIN" && "$K6_BIN" version
          echo "[ORR] BASE_URL=${BASE_URL:-http://127.0.0.1:8080}"
          bash scripts/orr_s4_run.sh

      - name: Bundle evidence (S4)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          bash scripts/orr_s4_bundle.sh

      - name: Upload bundle
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: s4_evidence_bundle
          path: out/s4_evidence_bundle_*.zip
