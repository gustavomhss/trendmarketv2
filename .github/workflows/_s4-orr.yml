name: _s4-orr

on:
  workflow_call:
    inputs:
      ref:
        description: Optional ref to run against
        required: false
        type: string
      run_microbench:
        description: Enable microbench gate
        required: false
        type: boolean
        default: false
      run_tla:
        description: Enable TLA verification
        required: false
        type: boolean
        default: false
      run_sut:
        description: Start SUT via compose/npm
        required: false
        type: boolean
        default: false
      bq_enable:
        description: Enable BigQuery path
        required: false
        type: boolean
        default: false
      run_sim:
        description: Run Sprint 5 simulations
        required: false
        type: boolean
        default: false
      run_dbt_ci:
        description: Run Sprint 5 dbt-ci with DuckDB
        required: false
        type: boolean
        default: false
      run_security:
        description: "Executar varreduras de segurança"
        required: false
        type: boolean
        default: false
      security_fail_on_findings:
        description: "Falhar se houver findings de segurança"
        required: false
        type: boolean
        default: false
    secrets:
      GCP_SA_JSON:
        required: false
      DBT_BQ_PROJECT:
        required: false
      DBT_BQ_DATASET:
        required: false
      DBT_BQ_LOCATION:
        required: false
      GHCR_APALACHE_TOKEN:
        required: false

concurrency:
  group: s4-orr-${{ inputs.ref || github.sha }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: write
  id-token: write

jobs:
  orr:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.sha }}

      - name: Security | Install Semgrep (pip<2)
        if: ${{ inputs.run_security }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/security
          if command -v semgrep >/dev/null 2>&1; then
            semgrep --version | tee out/security/semgrep-version.txt
            exit 0
          fi
          python3 -m pip install --upgrade "semgrep<2"
          semgrep --version | tee out/security/semgrep-version.txt

      - name: Security | Install Gitleaks (tarball)
        if: ${{ inputs.run_security }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/security
          if command -v gitleaks >/dev/null 2>&1; then
            gitleaks version | head -n1 | tee out/security/gitleaks-version.txt
            exit 0
          fi
          VER="8.18.1"
          URL="https://github.com/gitleaks/gitleaks/releases/download/v${VER}/gitleaks_${VER}_linux_x64.tar.gz"
          echo "[setup] Baixando Gitleaks ${VER}"
          curl -fsSL "$URL" -o gitleaks.tgz
          tar -xzf gitleaks.tgz gitleaks
          sudo install -m 0755 gitleaks /usr/local/bin/gitleaks
          rm -f gitleaks gitleaks.tgz
          gitleaks version | head -n1 | tee out/security/gitleaks-version.txt

      - name: Security | Install Trivy (candidate list)
        if: ${{ inputs.run_security }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/security
          if command -v trivy >/dev/null 2>&1; then
            trivy --version | head -n1 | tee out/security/trivy-version.txt
            exit 0
          fi
          sudo apt-get update
          mapfile -t TRIVY_CANDIDATES < <(apt-cache madison trivy | awk '{print $3}')
          if [ "${#TRIVY_CANDIDATES[@]}" -eq 0 ]; then
            echo "trivy indisponível no apt" | tee out/security/trivy-version.txt
            exit 0
          fi
          INSTALLED=1
          for ver in "${TRIVY_CANDIDATES[@]}"; do
            if sudo apt-get install -y "trivy=${ver}"; then
              INSTALLED=0
              break
            fi
          done
          if [ "$INSTALLED" -ne 0 ] || ! command -v trivy >/dev/null 2>&1; then
            echo "trivy indisponível após tentativas" | tee out/security/trivy-version.txt
            exit 0
          fi
          trivy --version | head -n1 | tee out/security/trivy-version.txt

      - name: Security | Semgrep scan
        if: ${{ inputs.run_security }}
        shell: bash
        continue-on-error: ${{ !inputs.security_fail_on_findings }}
        run: |
          set -euo pipefail
          mkdir -p out/security
          JSON="out/security/semgrep-report.json"
          LOG="out/security/semgrep-report.txt"
          : > "$LOG"
          set +e
          semgrep --config auto --json --output "$JSON" 2>&1 | tee "$LOG"
          STATUS=${PIPESTATUS[0]}
          set -e
          printf '%s\n' "$STATUS" > out/security/semgrep-exit-code.txt
          exit "$STATUS"

      - name: Security | Gitleaks detect
        if: ${{ inputs.run_security }}
        shell: bash
        continue-on-error: ${{ !inputs.security_fail_on_findings }}
        run: |
          set -euo pipefail
          mkdir -p out/security
          JSON="out/security/gitleaks-report.json"
          LOG="out/security/gitleaks-report.txt"
          : > "$LOG"
          set +e
          gitleaks detect --no-banner --report-format json --report-path "$JSON" 2>&1 | tee "$LOG"
          STATUS=${PIPESTATUS[0]}
          set -e
          printf '%s\n' "$STATUS" > out/security/gitleaks-exit-code.txt
          exit "$STATUS"

      - name: Security | Trivy fs (if available)
        if: ${{ inputs.run_security }}
        shell: bash
        continue-on-error: ${{ !inputs.security_fail_on_findings }}
        run: |
          set -euo pipefail
          mkdir -p out/security
          JSON="out/security/trivy-report.json"
          LOG="out/security/trivy-report.txt"
          if ! command -v trivy >/dev/null 2>&1; then
            echo "trivy não instalado; pulando varredura" | tee "$LOG"
            printf '{}\n' > "$JSON"
            printf '0\n' > out/security/trivy-exit-code.txt
            exit 0
          fi
          : > "$LOG"
          set +e
          trivy fs --scanners vuln,secret . --format json --output "$JSON" 2>&1 | tee "$LOG"
          STATUS=${PIPESTATUS[0]}
          set -e
          printf '%s\n' "$STATUS" > out/security/trivy-exit-code.txt
          exit "$STATUS"

      - name: Security | Upload findings
        if: ${{ always() && inputs.run_security }}
        uses: actions/upload-artifact@v4
        with:
          name: security-findings
          path: out/security/**
          if-no-files-found: warn

      - name: Mostrar versões das ferramentas
        shell: bash
        run: |
          set -euo pipefail
          echo "[setup] k6: $( (command -v k6 >/dev/null && k6 version) || echo 'não instalado ou usando Docker via K6_BIN')"
          echo "[setup] semgrep: $( (command -v semgrep >/dev/null && semgrep --version) || echo 'não instalado')"
          echo "[setup] trivy: $( (command -v trivy >/dev/null && trivy --version | head -n1) || echo 'não instalado')"
          echo "[setup] gitleaks: $( (command -v gitleaks >/dev/null && gitleaks version | head -n1) || echo 'não instalado')"

      - name: Localizar modelos TLA
        id: tla_scan
        if: ${{ inputs.run_tla }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out
          mapfile -t TLA_MODELS < <(git ls-files -z -- ':(glob)**/*.tla' | xargs -0 -r -n1 | sort -u)
          if [ "${#TLA_MODELS[@]}" -gt 0 ]; then
            printf '%s\n' "${TLA_MODELS[@]}" > out/tla_models.txt
            echo "have_tla=true" >> "$GITHUB_OUTPUT"
            echo "[tla] Modelos encontrados:"
            printf '  - %s\n' "${TLA_MODELS[@]}"
          else
            : > out/tla_models.txt
            echo "have_tla=false" >> "$GITHUB_OUTPUT"
            echo "[tla] Nenhum arquivo .tla encontrado; pulando checagens."
          fi

      - name: TLA ASCII guard (if exists)
        if: ${{ inputs.run_tla && steps.tla_scan.outputs.have_tla == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -x scripts/tla_ascii_guard.sh ]; then
            bash scripts/tla_ascii_guard.sh || {
              echo "[tla] ASCII guard falhou" >&2
              exit 1
            }
          else
            echo "[tla] scripts/tla_ascii_guard.sh não encontrado; pulando guard"
          fi

      - name: Detectar GHCR token
        id: ghcr_tok
        if: ${{ inputs.run_tla && steps.tla_scan.outputs.have_tla == 'true' }}
        shell: bash
        env:
          GHCR_APALACHE_TOKEN: ${{ secrets.GHCR_APALACHE_TOKEN }}
        run: |
          set -euo pipefail
          if [ -n "${GHCR_APALACHE_TOKEN:-}" ]; then
            echo "has_token=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_token=false" >> "$GITHUB_OUTPUT"
          fi

      - name: GHCR login (opcional)
        if: ${{ inputs.run_tla && steps.tla_scan.outputs.have_tla == 'true' && steps.ghcr_tok.outputs.has_token == 'true' }}
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_APALACHE_TOKEN }}

      - name: TLA check (Apalache)
        if: ${{ inputs.run_tla && steps.tla_scan.outputs.have_tla == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/s4_orr
          WORK="out/s4_orr/apalache_work"
          REPORT="out/s4_orr/tla_report.txt"
          rm -rf "$WORK"
          mkdir -p "$WORK/tmp"
          chmod 1777 "$WORK" "$WORK/tmp"
          : > "$REPORT"

          APAL_IMG="${APAL_IMG:-ghcr.io/apalache-mc/apalache:v0.50.3}"

          select_tla() {
            local base="$1"
            [ -d "$base" ] || return 1
            find "$base" -maxdepth 1 -type f -name '*.tla' | sort | head -n1
          }

          SEL=""
          if SEL=$(select_tla docs/spec/tla); then
            :
          else
            SEL=""
          fi
          if [ -z "$SEL" ]; then
            SEL=$(find . -maxdepth 1 -type f -name '*.tla' | sort | head -n1 || true)
          fi

          if [ -z "$SEL" ]; then
            echo "[tla] Nenhum arquivo .tla elegível encontrado" | tee -a "$REPORT"
            exit 1
          fi

          SEL_DIR="$(dirname "$SEL")"
          find "$SEL_DIR" -maxdepth 1 -type f -name '*.tla' -exec cp -f {} "$WORK/" \;
          if [ -d docs/spec/tla ]; then
            find docs/spec/tla -type f -name '*.tla' -exec cp -f {} "$WORK/" \;
          fi

          MODULE="$(basename "$SEL")"
          MOUNT_PATH="$PWD/$WORK"

          { 
            echo "[tla] Using image: ${APAL_IMG}"
            echo "[tla] Selected module: ${MODULE}"
            echo "[tla] Workspace: ${WORK}"
          } | tee -a "$REPORT"

          APAL_UID="$(id -u)"
          APAL_GID="$(id -g)"
          APAL_USER="$(id -un)"

          set +e
          docker run --rm \
            -e "APAL_UID=${APAL_UID}" \
            -e "APAL_GID=${APAL_GID}" \
            -e "APAL_USER=${APAL_USER}" \
            -v "${MOUNT_PATH}:/var/apalache" \
            -w /var/apalache \
            "$APAL_IMG" \
            check "$MODULE" | tee -a "$REPORT"
          RC=${PIPESTATUS[0]}
          set -e

          if command -v sudo >/dev/null 2>&1; then
            sudo chown -R "${APAL_UID}:${APAL_GID}" "$WORK" || true
            sudo chmod -R u+rwX,go+rX "$WORK" || true
          else
            chmod -R u+rwX,go+rX "$WORK" || true
          fi

          echo "[tla] Exit code: ${RC}" | tee -a "$REPORT"
          exit "$RC"

      - name: Upload TLA report
        uses: actions/upload-artifact@v4
        if: ${{ always() && inputs.run_tla && steps.tla_scan.outputs.have_tla == 'true' }}
        with:
          name: tla-report
          path: out/s4_orr/tla_report.txt
          if-no-files-found: warn

      - name: dbt run (DuckDB)
        if: ${{ !inputs.run_tla && hashFiles('dbt_project.yml') != '' }}
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install 'dbt-duckdb~=1.8.0'
          mkdir -p out/dbt out/dbt/tmp "$HOME/.dbt"
          if [ -f ops/dbt/profiles_duckdb.yml ]; then
            cp ops/dbt/profiles_duckdb.yml "$HOME/.dbt/profiles.yml"
          else
            {
              echo "ce_profile:"
              echo "  target: ci"
              echo "  outputs:"
              echo "    ci:"
              echo "      type: duckdb"
              echo "      path: ./out/dbt/ce.duckdb"
              echo "      threads: 4"
              echo "      extensions: [httpfs]"
              echo "      settings:"
              echo "        temp_directory: \"./out/dbt/tmp\""
              echo "        memory_limit: \"1GB\""
            } > "$HOME/.dbt/profiles.yml"
          fi
          dbt deps --profiles-dir "$HOME/.dbt" --profile ce_profile
          dbt debug --profiles-dir "$HOME/.dbt" --profile ce_profile
          dbt run --profiles-dir "$HOME/.dbt" --profile ce_profile

      - name: Iniciar SUT (Compose/npm)
        if: ${{ !inputs.run_tla && inputs.run_sut }}
        shell: bash
        run: |
          set -euo pipefail
          echo "[sut] preparing start"
          mkdir -p out
          LOG_FILE="out/sut.log"
          : > "$LOG_FILE"
          echo "[sut] log file: $LOG_FILE"
          if [ "${EXTERNAL_SUT:-0}" = "1" ]; then
            echo "[sut] EXTERNAL_SUT=1 -> não iniciaremos processos locais"
            exit 0
          fi
          FILE=""
          for f in docker-compose.yml docker-compose.yaml compose.yaml; do
            if [ -f "$f" ]; then FILE="$f"; break; fi
          done
          if [ -n "$FILE" ] && command -v docker >/dev/null 2>&1; then
            echo "[sut] docker compose -f $FILE up -d --build"
            docker compose -f "$FILE" up -d --build
          else
            echo "[sut] docker/compose ausentes; nada a fazer"
          fi

      - name: "S5 Simulation — run deterministic scenarios"
        if: ${{ inputs.run_sim }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/sim
          SEED=42 python -m tools.sim_harness --fixtures fixtures --scenario spike --out out/sim/spike.report.json
          SEED=42 python -m tools.sim_harness --fixtures fixtures --scenario gap --out out/sim/gap.report.json
          SEED=42 python -m tools.sim_harness --fixtures fixtures --scenario burst --out out/sim/burst.report.json

      - name: "S5 DBT (DuckDB) — deps/debug/run/test"
        if: ${{ inputs.run_dbt_ci || hashFiles('dbt_project.yml') != '' }}
        shell: bash
        run: |
          set -euo pipefail
          python3 -m pip install --upgrade 'dbt-duckdb~=1.8.0'
          mkdir -p out/dbt
          mkdir -p "$HOME/.dbt"
          if [ ! -f "$HOME/.dbt/profiles.yml" ]; then
            python3 -c "from pathlib import Path; profile_path = Path.home() / '.dbt' / 'profiles.yml'; profile_path.write_text('ce_profile:\n  target: duckdb\n  outputs:\n    duckdb:\n      type: duckdb\n      path: out/dbt/ce.duckdb\n      schema: main\n      threads: 4\n')"
          fi
          dbt deps --profiles-dir "$HOME/.dbt" --profile ce_profile
          dbt debug --profiles-dir "$HOME/.dbt" --profile ce_profile
          dbt run --profiles-dir "$HOME/.dbt" --profile ce_profile
          dbt test --profiles-dir "$HOME/.dbt" --profile ce_profile

      - name: Empacotar evidências (S4)
        if: ${{ always() && !inputs.run_tla }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out
          TS=$(date +%Y%m%d_%H%M%S)
          BUNDLE="out/s4_evidence_bundle_${TS}"

          if [ -x scripts/orr_s4_bundle.sh ]; then
            echo "[bundle] Executando scripts/orr_s4_bundle.sh"
            bash scripts/orr_s4_bundle.sh
          else
            echo "[bundle] Script de bundle ausente; usando fallback"
            mkdir -p "${BUNDLE}"
            copy_if_exists() {
              local path="$1"
              local dest="$2"
              if [ -e "$path" ]; then
                echo "[bundle] Incluindo $path"
                cp -r "$path" "$dest/" || true
              else
                echo "[bundle] Ausente: $path (ok)"
              fi
            }

            echo "[bundle] Coletando diretórios alvo"
            copy_if_exists out/s4_orr "${BUNDLE}"
            copy_if_exists out/pip-audit "${BUNDLE}"

            if TARGETS=$(find analytics -type d -name target -print -quit 2>/dev/null) && [ -n "${TARGETS:-}" ]; then
              echo "[bundle] Incluindo analytics/**/target"
              while IFS= read -r -d '' target; do
                rel_path="${target#analytics/}"
                dest_dir="${BUNDLE}/analytics/${rel_path%/target}"
                mkdir -p "$dest_dir"
                cp -r "$target" "$dest_dir/" || true
              done < <(find analytics -type d -name target -print0)
            else
              echo "[bundle] Ausente: analytics/**/target (ok)"
            fi

            copy_if_exists docs/ADRs "${BUNDLE}"
            copy_if_exists docs/runbooks "${BUNDLE}"
            copy_if_exists ops/watchers.yml "${BUNDLE}"
            copy_if_exists scripts/microbench_dec.sh "${BUNDLE}"
            copy_if_exists benches "${BUNDLE}"
            copy_if_exists out/sut.log "${BUNDLE}"

            if command -v zip >/dev/null 2>&1; then
              echo "[bundle] Compactando em zip"
              (cd out && zip -r "$(basename "${BUNDLE}").zip" "$(basename "${BUNDLE}")")
              rm -rf "${BUNDLE}"
            else
              echo "[bundle] zip ausente; usando tar.gz"
              tar -C out -czf "${BUNDLE}.tar.gz" "$(basename "${BUNDLE}")"
              rm -rf "${BUNDLE}"
            fi
          fi

      - name: Upload bundle
        if: ${{ always() && !inputs.run_tla }}
        uses: actions/upload-artifact@v4
        with:
          name: s4-bundle
          path: |
            out/s4_evidence_bundle_*.zip
            out/s4_evidence_bundle_*.tar.gz
          if-no-files-found: ignore

      - name: Upload auditoria pip
        if: ${{ always() && !inputs.run_tla }}
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit
          path: out/pip-audit
          if-no-files-found: ignore

      - name: Upload s4-orr evidence
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: s4-orr-evidence
          path: |
            out/**
            out/dbt/**
            out/apalache/**
            target/**
            logs/**
          if-no-files-found: warn
