# ---------- .github/workflows/_s4-orr.yml ----------
name: _s4-orr

on:
  workflow_call:
    inputs:
      ref:
        description: Optional ref to run against
        required: false
        type: string
      run_microbench:
        description: Enable microbench gate
        required: false
        type: boolean
        default: false
      run_tla:
        description: Enable TLA verification
        required: false
        type: boolean
        default: false
    secrets:
      GCP_SA_JSON:
        required: false
      DBT_BQ_PROJECT:
        required: false
      DBT_BQ_DATASET:
        required: false
      DBT_BQ_LOCATION:
        required: false

concurrency:
  group: "s4-orr-${{ inputs.ref || github.sha }}"
  cancel-in-progress: true

permissions:
  contents: read
  actions: write

jobs:
  orr:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    env:
      PROM_URL: http://127.0.0.1:9090

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.sha }}

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install base tools (jq, k6, semgrep)
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq curl ca-certificates gnupg
          curl -fsSL https://dl.k6.io/key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/k6-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install -y k6
          python -m pip install --upgrade pip
          python -m pip install "semgrep<2"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          k6 version
          semgrep --version

      - name: Install security tools (Trivy & Gitleaks)
        shell: bash
        run: |
          set -euo pipefail
          curl -sSL https://github.com/gitleaks/gitleaks/releases/download/v8.18.4/gitleaks_8.18.4_linux_x64.tar.gz | tar xz
          sudo install -m 0755 gitleaks /usr/local/bin/gitleaks
          rm -f gitleaks LICENSE README.md || true

          curl -sSL https://github.com/aquasecurity/trivy/releases/download/v0.53.0/trivy_0.53.0_Linux-64bit.tar.gz | tar xz
          sudo install -m 0755 trivy /usr/local/bin/trivy
          rm -f trivy LICENSE README.md || true

      - name: Setup Node 20
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install npm deps (if lockfile)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f package-lock.json ] || [ -f npm-shrinkwrap.json ]; then
            npm ci --ignore-scripts
          else
            echo "no package-lock.json; skipping npm ci"
          fi

      - name: Setup Python deps (dbt only)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "dbt-core==1.6.4" "dbt-bigquery==1.6.4" "requests==2.31.0"

      - name: Python env audit
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/pip-audit
          python -m pip --version | tee out/pip-audit/pip-version.txt
          pip freeze | sort | tee out/pip-audit/pip-freeze.txt

      - name: Upload pip audit
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit
          path: out/pip-audit

      - name: Ensure script perms
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/microbench_dec.sh scripts/orr_s4_bundle.sh scripts/orr_s4_run.sh || true

      # -------- dbt (optional) --------
      - name: Locate dbt project
        id: dbt
        shell: bash
        run: |
          set -euo pipefail
          DBT_DIR=$(find . -type f -name dbt_project.yml | head -n1 | xargs -r dirname)
          if [ -n "$DBT_DIR" ]; then
            echo "dir=$DBT_DIR" >> "$GITHUB_OUTPUT"
            echo "Found dbt project at $DBT_DIR"
          else
            echo "dir=" >> "$GITHUB_OUTPUT"
            echo "No dbt project found; skipping dbt steps."
          fi

      - name: Configure BigQuery credentials for dbt (if secrets present)
        id: bq
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${GCP_SA_JSON:-}" ] && [ -n "${DBT_BQ_PROJECT:-}" ]; then
            echo "have_secrets=true" >> "$GITHUB_OUTPUT"
          else
            echo "have_secrets=false" >> "$GITHUB_OUTPUT"
          fi

      - name: dbt deps
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        shell: bash
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt deps --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: dbt build
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        shell: bash
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt build --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: dbt docs generate
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        shell: bash
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt docs generate --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: Upload dbt docs
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: dbt-docs
          path: |
            ${{ steps.dbt.outputs.dir }}/target/catalog.json
            ${{ steps.dbt.outputs.dir }}/target/manifest.json
            ${{ steps.dbt.outputs.dir }}/target/index.html

      # -------- TLA (optional) --------
      - name: Locate TLA models
        id: tla
        if: ${{ inputs.run_tla }}
        shell: bash
        run: |
          set -euo pipefail
          TLA_LIST=$(git ls-files 'docs/spec/tla/*.tla' 2>/dev/null; git ls-files '*.tla' 2>/dev/null)
          if [ -n "$TLA_LIST" ]; then
            echo "have_tla=true" >> "$GITHUB_OUTPUT"
            SEL=$(printf '%s\n' "$TLA_LIST" | head -n1)
            echo "tla_file=$SEL" >> "$GITHUB_OUTPUT"
            echo "[tla] found models:"
            printf '  - %s\n' $TLA_LIST
            echo "[tla] selected: $SEL"
          else
            echo "have_tla=false" >> "$GITHUB_OUTPUT"
            echo "[tla] no .tla files found; skipping TLA steps."
          fi

      - name: Apalache (pull + smoke)
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        env:
          APAL_IMG_PRIMARY: ghcr.io/apalache-mc/apalache:v0.50.3
          APAL_IMG_FALLBACK: ghcr.io/apalache-mc/apalache:main
        shell: bash
        run: |
          set -euo pipefail
          command -v docker >/dev/null || { echo "docker missing on runner"; exit 1; }
          if ! docker pull "$APAL_IMG_PRIMARY" >/dev/null 2>&1; then
            echo "[apalache] v0.50.3 unavailable; using :main"
            docker pull "$APAL_IMG_FALLBACK" >/dev/null
            APAL_IMG="$APAL_IMG_FALLBACK"
          else
            APAL_IMG="$APAL_IMG_PRIMARY"
          fi
          echo "APAL_IMG=$APAL_IMG" >> "$GITHUB_ENV"
          set +e
          docker run --rm --entrypoint /bin/sh "$APAL_IMG" -c 'echo apalache image ok'
          RC=$?
          if [ $RC -ne 0 ]; then
            docker run --rm -u 0:0 --entrypoint /bin/sh "$APAL_IMG" -c 'echo apalache image ok'
          fi
          set -e

      - name: TLA ASCII guard (if exists)
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -x scripts/tla_ascii_guard.sh ]; then
            bash scripts/tla_ascii_guard.sh
          else
            echo "tla_ascii_guard.sh missing; continuing"
          fi

      - name: TLA check (Apalache)
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/s4_orr out/s4_orr/apalache_work out/s4_orr/apalache_work/tmp
          SEL="${{ steps.tla.outputs.tla_file }}"
          SEL_DIR=$(dirname "$SEL")
          SEL_FILE=$(basename "$SEL")
          cp -f "$SEL_DIR"/*.tla out/s4_orr/apalache_work/ || true
          chmod -R 777 out/s4_orr/apalache_work
          set +e
          docker run --rm \
            -v "$PWD/out/s4_orr/apalache_work:/var/apalache" \
            "$APAL_IMG" check "$SEL_FILE" | tee out/s4_orr/tla_report.txt
          RC=$?
          set -e
          if [ $RC -ne 0 ]; then
            echo "[tla] retrying as root due to permissions..."
            docker run --rm -u 0:0 \
              -v "$PWD/out/s4_orr/apalache_work:/var/apalache" \
              "$APAL_IMG" check "$SEL_FILE" | tee out/s4_orr/tla_report.txt
          fi

      - name: Upload TLA report
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: tla-report
          path: out/s4_orr/tla_report.txt

      # -------- ORR main --------
      - name: Microbench (gate)
        if: ${{ inputs.run_microbench }}
        shell: bash
        run: |
          set -euo pipefail
          bash scripts/microbench_dec.sh

      - name: Start SUT (compose/npm) or WireMock fallback
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out
          echo "[SUT] Starting..."

          if command -v docker >/dev/null && { [ -f docker-compose.yml ] || [ -f compose.yaml ] || [ -f docker-compose.yaml ]; }; then
            FILE=$( [ -f docker-compose.yml ] && echo docker-compose.yml || ( [ -f compose.yaml ] && echo compose.yaml || echo docker-compose.yaml ) )
            echo "[SUT] docker compose -f $FILE up -d"
            docker compose -f "$FILE" up -d
          else
            if [ -f package.json ] && jq -e '.scripts["start:ci"]' package.json >/dev/null; then
              echo "[SUT] npm run start:ci (background)"
              nohup npm run start:ci > out/sut.log 2>&1 &
            elif [ -f package.json ] && jq -e '.scripts["start"]' package.json >/dev/null; then
              echo "[SUT] npm start (background)"
              nohup npm start > out/sut.log 2>&1 &
            else
              echo "[SUT] No compose/npm; starting WireMock fallback on :8080"
              docker rm -f sut >/dev/null 2>&1 || true
              docker run -d --name sut -p 8080:8080 ghcr.io/wiremock/wiremock:3.9.1
              # wait admin up
              for i in $(seq 1 30); do
                if curl -fsS http://127.0.0.1:8080/__admin/ >/dev/null; then break; fi; sleep 1; done
              # create stubs
              curl -sS -X POST http://127.0.0.1:8080/__admin/mappings \
                -H 'Content-Type: application/json' \
                -d '{"request":{"method":"GET","url":"/health"},"response":{"status":200,"headers":{"Content-Type":"application/json"},"jsonBody":{"status":"UP"}}}'
              curl -sS -X POST http://127.0.0.1:8080/__admin/mappings \
                -H 'Content-Type: application/json' \
                -d '{"request":{"method":"GET","urlPath":"/decisions"},"response":{"status":200,"headers":{"Content-Type":"application/json"},"jsonBody":{"ok":true}}}'
            fi
          fi

      - name: Wait for SUT /health
        shell: bash
        run: |
          set -euo pipefail
          SUT_URL="${SUT_URL:-http://127.0.0.1:8080/health}"
          echo "[SUT] waiting for $SUT_URL ..."
          for i in $(seq 1 60); do
            if curl -fsS "$SUT_URL" >/dev/null; then
              echo "[SUT] ready"; exit 0; fi
            sleep 2
          done
          echo "[SUT] not ready after timeout" >&2
          echo "::group::SUT logs"
          if command -v docker >/dev/null && { [ -f docker-compose.yml ] || [ -f compose.yaml ] || [ -f docker-compose.yaml ]; }; then
            docker compose logs --no-color --tail 200 || true
          fi
          [ -f out/sut.log ] && tail -n 200 out/sut.log || true
          echo "::endgroup::"
          exit 1

      - name: ORR run
        env:
          K6_BIN: k6
        shell: bash
        run: |
          set -euo pipefail
          export BASE_URL="${BASE_URL:-${SUT_URL%/health}}"
          [ -z "$BASE_URL" ] && export BASE_URL="http://127.0.0.1:8080"
          export DEC_BASE_URL="${DEC_BASE_URL:-$BASE_URL}"
          echo "[ORR] Using BASE_URL=$BASE_URL"
          bash scripts/orr_s4_run.sh

      - name: Bundle evidence (S4)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          bash scripts/orr_s4_bundle.sh

      - name: Cleanup SUT
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          docker rm -f sut >/dev/null 2>&1 || true

      - name: Upload bundle
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: s4_evidence_bundle
          path: out/s4_evidence_bundle_*.zip
