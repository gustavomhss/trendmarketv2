# ---------- .github/workflows/_s4-orr.yml ----------
name: _s4-orr

on:
  workflow_call:
    inputs:
      ref:
        description: "Optional ref to run against"
        required: false
        type: string
      run_microbench:
        description: "Enable microbench gate"
        required: false
        type: boolean
        default: false
      run_tla:
        description: "Enable TLA verification"
        required: false
        type: boolean
        default: false
      base_url:
        description: "URL do SUT (ex.: https://api.seudominio.com ou http://127.0.0.1:8080)"
        required: false
        type: string
        default: "http://127.0.0.1:8080"
    secrets:
      GCP_SA_JSON:
        required: false
      DBT_BQ_PROJECT:
        required: false
      DBT_BQ_DATASET:
        required: false
      DBT_BQ_LOCATION:
        required: false

concurrency:
  group: "s4-orr-${{ inputs.ref || github.sha }}"
  cancel-in-progress: true

permissions:
  contents: read
  actions: write

jobs:
  orr:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    env:
      PROM_URL: http://127.0.0.1:9090

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.sha }}

      - name: Harden runner
        uses: step-security/harden-runner@v2
        with:
          egress-policy: audit

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install jq + curl + gpg
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq curl ca-certificates gnupg

      - name: Install k6 (native)
        shell: bash
        run: |
          set -euo pipefail
          curl -fsSL https://dl.k6.io/key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/k6-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install -y k6
          k6 version

      - name: Install Semgrep CLI (pip)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install "semgrep<2"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          semgrep --version

      # -------- Python deps (dbt only) + auditoria --------
      - name: Install Python deps (dbt only)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "dbt-core==1.6.4" "dbt-bigquery==1.6.4" "requests==2.31.0"

      - name: Python env audit
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/pip-audit
          python -m pip --version | tee out/pip-audit/pip-version.txt
          pip freeze | sort | tee out/pip-audit/pip-freeze.txt

      - name: Upload pip audit
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit
          path: out/pip-audit

      # -------- Ferramentas de segurança (binários) --------
      - name: Install security tools (Trivy & Gitleaks)
        shell: bash
        run: |
          set -euo pipefail
          curl -sSL https://github.com/gitleaks/gitleaks/releases/download/v8.18.4/gitleaks_8.18.4_linux_x64.tar.gz | tar xz
          sudo install -m 0755 gitleaks /usr/local/bin/gitleaks
          rm -f gitleaks LICENSE README.md || true

          curl -sSL https://github.com/aquasecurity/trivy/releases/download/v0.53.0/trivy_0.53.0_Linux-64bit.tar.gz | tar xz
          sudo install -m 0755 trivy /usr/local/bin/trivy
          rm -f trivy LICENSE README.md || true

      - name: Semgrep (container v1.80.0, pinned digest)
        shell: bash
        run: |
          set -euo pipefail
          SEMGREP_IMG="semgrep/semgrep:1.80.0-nonroot@sha256:a80fcd5ce03772efeca8fc58f0eeb7ede05c228c8b12c1e078601a4f52de75a4"
          docker pull "$SEMGREP_IMG" >/dev/null
          docker run --rm -v "$PWD:/src" -w /src "$SEMGREP_IMG" semgrep --version
          # opcional: varredura
          # docker run --rm -v "$PWD:/src" -w /src "$SEMGREP_IMG" semgrep --config auto --error --timeout 120 .

      # -------- Node (opcional) --------
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install npm deps
        shell: bash
        run: |
          set -euo pipefail
          if [ -f package-lock.json ] || [ -f npm-shrinkwrap.json ]; then
            npm ci --ignore-scripts
          else
            echo "no package-lock.json; skipping npm ci"
          fi

      - name: Permissions
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/microbench_dec.sh scripts/orr_s4_bundle.sh scripts/orr_s4_run.sh || true

      # -------- k6 digest (mantido para referência; não é obrigatório) --------
      - name: Resolve k6 digest
        id: k6
        shell: bash
        run: |
          set -euo pipefail
          IMAGE=grafana/k6:0.52.0
          docker pull "$IMAGE" >/dev/null
          DIGEST=$(docker inspect --format='{{index .RepoDigests 0}}' "$IMAGE")
          echo "image=$DIGEST" >> "$GITHUB_OUTPUT"

      # -------- dbt build → dbt docs (somente se houver projeto dbt) --------
      - name: Locate dbt project
        id: dbt
        shell: bash
        run: |
          set -euo pipefail
          DBT_DIR=$(find . -type f -name dbt_project.yml | head -n1 | xargs -r dirname)
          if [ -n "$DBT_DIR" ]; then
            echo "dir=$DBT_DIR" >> "$GITHUB_OUTPUT"
            echo "Found dbt project at $DBT_DIR"
          else
            echo "dir=" >> "$GITHUB_OUTPUT"
            echo "No dbt project found; skipping dbt steps."
          fi

      - name: Configure BigQuery credentials for dbt (if secrets present)
        id: bq
        shell: bash
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        run: |
          set -euo pipefail
          if [ -n "${GCP_SA_JSON:-}" ] && [ -n "${DBT_BQ_PROJECT:-}" ]; then
            echo "have_secrets=true" >> "$GITHUB_OUTPUT"
          else
            echo "have_secrets=false" >> "$GITHUB_OUTPUT"
          fi

      - name: dbt deps
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        shell: bash
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt deps --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: dbt build
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        shell: bash
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt build --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: dbt docs generate
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        shell: bash
        env:
          GCP_SA_JSON: ${{ secrets.GCP_SA_JSON }}
          DBT_BQ_PROJECT: ${{ secrets.DBT_BQ_PROJECT }}
          DBT_BQ_DATASET: ${{ secrets.DBT_BQ_DATASET }}
          DBT_BQ_LOCATION: ${{ secrets.DBT_BQ_LOCATION }}
        run: |
          set -euo pipefail
          DBT_DIR="${{ steps.dbt.outputs.dir }}"
          dbt docs generate --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR/profiles"

      - name: Upload dbt docs
        if: ${{ steps.dbt.outputs.dir != '' && steps.bq.outputs.have_secrets == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: dbt-docs
          path: |
            ${{ steps.dbt.outputs.dir }}/target/catalog.json
            ${{ steps.dbt.outputs.dir }}/target/manifest.json
            ${{ steps.dbt.outputs.dir }}/target/index.html

      # -------- Microbench gate (opcional) --------
      - name: Microbench (gate)
        if: ${{ inputs.run_microbench }}
        shell: bash
        run: |
          set -euo pipefail
          bash scripts/microbench_dec.sh

      # -------- TLA check (opcional) --------
      - name: Locate TLA models
        id: tla
        if: ${{ inputs.run_tla }}
        shell: bash
        run: |
          set -euo pipefail
          TLA_GLOB=$(git ls-files 'docs/spec/tla/*.tla' || true)
          if [ -z "$TLA_GLOB" ]; then
            TLA_GLOB=$(git ls-files '*.tla' || true)
          fi
          if [ -n "$TLA_GLOB" ]; then
            echo "have_tla=true" >> "$GITHUB_OUTPUT"
            SEL=$(printf "%s\n" "$TLA_GLOB" | head -n1)
            echo "tla_file=$SEL" >> "$GITHUB_OUTPUT"
            echo "[tla] found models:"; printf "  - %s\n" $TLA_GLOB
            echo "[tla] selected: $SEL"
          else
            echo "have_tla=false" >> "$GITHUB_OUTPUT"
            echo "[tla] no .tla files found; skipping TLA steps."
          fi

      - name: Apalache (pull + smoke)
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        shell: bash
        env:
          APAL_IMG_PRIMARY: ghcr.io/apalache-mc/apalache:v0.50.3
          APAL_IMG_FALLBACK: ghcr.io/apalache-mc/apalache:main
        run: |
          set -euo pipefail
          command -v docker >/dev/null || { echo "docker not present"; exit 1; }
          if ! docker pull "$APAL_IMG_PRIMARY" >/dev/null 2>&1; then
            echo "[apalache] v0.50.3 unavailable; using :main"
            docker pull "$APAL_IMG_FALLBACK" >/dev/null
            APAL_IMG="$APAL_IMG_FALLBACK"
          else
            APAL_IMG="$APAL_IMG_PRIMARY"
          fi
          echo "APAL_IMG=$APAL_IMG" >> "$GITHUB_ENV"
          set +e
          docker run --rm --entrypoint /bin/sh "$APAL_IMG" -c 'echo apalache image ok'
          RC=$?
          if [ $RC -ne 0 ]; then
            docker run --rm -u 0:0 --entrypoint /bin/sh "$APAL_IMG" -c 'echo apalache image ok'
          fi
          set -e

      - name: TLA ASCII guard
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        shell: bash
        run: |
          bash scripts/tla_ascii_guard.sh

      - name: TLA check (Apalache)
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out/s4_orr out/s4_orr/apalache_work out/s4_orr/apalache_work/tmp
          SEL="${{ steps.tla.outputs.tla_file }}"
          SEL_DIR=$(dirname "$SEL")
          SEL_FILE=$(basename "$SEL")
          cp -f "$SEL_DIR"/*.tla out/s4_orr/apalache_work/ || true
          chmod -R 777 out/s4_orr/apalache_work
          set +e
          docker run --rm \
            -v "$PWD/out/s4_orr/apalache_work:/var/apalache" \
            "$APAL_IMG" check "$SEL_FILE" | tee out/s4_orr/tla_report.txt
          RC=$?
          set -e
          if [ $RC -ne 0 ]; then
            echo "[tla] retrying as root due to permissions..."
            docker run --rm -u 0:0 \
              -v "$PWD/out/s4_orr/apalache_work:/var/apalache" \
              "$APAL_IMG" check "$SEL_FILE" | tee out/s4_orr/tla_report.txt
          fi

      - name: Upload TLA report
        if: ${{ inputs.run_tla && steps.tla.outputs.have_tla == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: tla-report
          path: out/s4_orr/tla_report.txt

      # -------- SUT: probe and local fallback (only for local base_url) --------
      - name: Probe/Start SUT (fallback only if local BASE_URL and down)
        shell: bash
        env:
          BASE_URL_INPUT: ${{ inputs.base_url }}
        run: |
          set -euo pipefail
          BASE_URL="${BASE_URL_INPUT%/}"
          DECISIONS_URL="${BASE_URL}/decisions"

          echo "[SUT] Probing ${DECISIONS_URL} ..."
          for i in $(seq 1 10); do
            if curl -fsS "${DECISIONS_URL}" >/dev/null; then
              echo "[SUT] Up at ${BASE_URL}"
              echo "BASE_URL=${BASE_URL}" >> "$GITHUB_ENV"
              echo "DEC_BASE_URL=${BASE_URL}" >> "$GITHUB_ENV"
              exit 0
            fi
            sleep 2
          done

          case "${BASE_URL}" in
            http://127.0.0.1*|http://localhost*)
              echo "[SUT] No local SUT; starting minimal fallback on :8080"
              python3 - <<'PY' &
import json, http.server, socketserver
class H(http.server.BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path.startswith("/health"):
            self.send_response(200); self.end_headers(); self.wfile.write(b"ok"); return
        if self.path.startswith("/decisions"):
            self.send_response(200); self.send_header("Content-Type","application/json")
            self.end_headers(); self.wfile.write(json.dumps({"items": []}).encode()); return
        self.send_response(404); self.end_headers()
    def log_message(self, *a, **k): pass
with socketserver.TCPServer(("0.0.0.0", 8080), H) as httpd:
    httpd.serve_forever()
PY
              echo $! > /tmp/sut.pid
              for i in $(seq 1 30); do
                if curl -fsS "${DECISIONS_URL}" >/dev/null; then
                  echo "[SUT] Fallback ready at ${BASE_URL}"
                  echo "BASE_URL=${BASE_URL}" >> "$GITHUB_ENV"
                  echo "DEC_BASE_URL=${BASE_URL}" >> "$GITHUB_ENV"
                  exit 0
                fi
                sleep 1
              done
              echo "[SUT] Fallback failed to become ready."
              exit 1
              ;;
            *)
              echo "[SUT] Remote SUT ${BASE_URL} is unreachable; refusing fallback."
              exit 1
              ;;
          esac

      # -------- ORR principal --------
      - name: ORR run
        env:
          K6_BIN: k6
        shell: bash
        run: |
          set -euo pipefail
          echo "[ORR] Using BASE_URL=${BASE_URL:-unset}"
          echo "[ORR] Using DEC_BASE_URL=${DEC_BASE_URL:-unset}"
          "$K6_BIN" version
          bash scripts/orr_s4_run.sh

      - name: Bundle evidence (S4)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          bash scripts/orr_s4_bundle.sh

      - name: Upload bundle
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: s4_evidence_bundle
          path: out/s4_evidence_bundle_*.zip
